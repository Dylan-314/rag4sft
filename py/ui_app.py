"""Unified Streamlit UI for RAG-SFT System"""

import os
import streamlit as st
from dotenv import load_dotenv

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 0. å…¨å±€ä¸€æ¬¡æ€§é…ç½®
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="RAG-SFT System", layout="wide")
load_dotenv()
os.environ["OPENAI_API_BASE"] = "https://api.v3.cm/v1"   # æ˜¾å¼æŒ‡å®š

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. å¯¼å…¥å­é¡µé¢
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

from importlib import import_module

chat_ui       = import_module("mod.chat.streamlit_app")
retriever_ui  = import_module("mod.retriever.streamlit_app")
qgen_ui       = import_module("mod.question_generator.streamlit_app")
ans_ui        = import_module("mod.answer_generator.streamlit_app")
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. é¡µé¢æ˜ å°„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PAGES = {
    "ğŸ’¬ General Chat": chat_ui.render,
    "ğŸ“š Knowledge Retriever": retriever_ui.render,
    "â“ Question Generator": qgen_ui.render,
    "ğŸ“ Answer Generator": ans_ui.render,
    "ğŸ“Š LangSmith Evaluation": "EVAL",   # å ä½ï¼Œç‰¹æ®Šæ¸²æŸ“
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. Sidebar å¯¼èˆª
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.title("ğŸ”— Navigation")
page = st.sidebar.radio(
    "Go to",
    list(PAGES.keys()),
    key="nav_page_select",
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. é¡µé¢è°ƒåº¦
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if page == "ğŸ“Š LangSmith Evaluation":
    # -------------- EVAL é¡µ --------------
    st.header("ğŸ“Š LangSmith Evaluation Dashboard")

    from langsmith import Client, evaluate
    ls_client = Client()

    dataset_name = st.text_input(
        "Dataset name on LangSmith",
        value="my_dataset",
        key="eval_dataset_name",
    )
    model_name = st.selectbox(
        "LLM model",
        ["gpt-4.1", "deepseek-r1", "gemini-2.5-pro-preview-05-06"],
        key="eval_model_name",
    )

    if st.button("ğŸš€ Run evaluation", key="eval_run"):
        if not dataset_name.strip():
            st.warning("âš ï¸ è¯·å…ˆå¡«å†™æ•°æ®é›†åç§°")
            st.stop()
        with st.spinner("Running evaluation â€¦"):
            # ç›®æ ‡å‡½æ•°ï¼šç®€å•è°ƒç”¨ answer_generator
            from langchain.docstore.document import Document
            from mod.answer_generator.answer_generator import generate_answer

            def target_fn(example):
                doc = Document(page_content=example["input"])
                return generate_answer(
                    example["instruction"],
                    [doc],
                    model=model_name,
                )

            results = evaluate(
                target_fn,
                dataset_name=dataset_name,
                evaluators=["qa"],
                client=ls_client,
            )
        st.success("âœ… Finish!")
        st.dataframe(results, use_container_width=True)
else:
    # -------------- å…¶å®ƒå­é¡µé¢ --------------
    PAGES[page]()               # è°ƒç”¨å¯¹åº”æ¨¡å—çš„ render()